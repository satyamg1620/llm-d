apiVersion: apps/v1
kind: Deployment
metadata:
  name: interactive-pod
  labels:
    app: interactive-pod
spec:
  replicas: 1
  revisionHistoryLimit: 2
  strategy:
    type: Recreate # don't run two interactive pods at once during updates
  selector:
    matchLabels:
      app: interactive-pod
  template:
    metadata:
      labels:
        app: interactive-pod
    spec:
      serviceAccountName: interactive-pod
      containers:
        - name: benchmark-runner
          # image: "ghcr.io/llm-d/interactive-pod:latest"
          image: "vllm/vllm-openai:latest"
          imagePullPolicy: Always
          command: ["bash", "-lc", "sleep infinity"]
          tty: true
          stdin: true
          resources:
            requests:
              nvidia.com/gpu: 1
              cpu: "8"
              memory: "16Gi"
            limits:
              nvidia.com/gpu: 1
              cpu: "8"
              memory: "16Gi"
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      # optional: shorten shutdowns for faster restarts
      terminationGracePeriodSeconds: 10
